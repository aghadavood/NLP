{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [],
      "dockerImageVersionId": 30733,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "QaPersian-bert-fa-base-uncased",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aghadavood/NLP/blob/main/QaPersian_bert_fa_base_uncased.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
        "\n",
        "model_name = \"HooshvareLab/bert-fa-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_name)\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-06-17T22:21:31.54452Z",
          "iopub.execute_input": "2024-06-17T22:21:31.544872Z",
          "iopub.status.idle": "2024-06-17T22:21:41.530611Z",
          "shell.execute_reply.started": "2024-06-17T22:21:31.544846Z",
          "shell.execute_reply": "2024-06-17T22:21:41.52984Z"
        },
        "trusted": true,
        "id": "RzlfdJylWFWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "def tokenize_dataset(dataset, tokenizer):\n",
        "    def preprocess_function(examples):\n",
        "        questions = examples['question']\n",
        "        contexts = examples['context']\n",
        "        answers = examples['answers']\n",
        "\n",
        "        inputs = tokenizer(questions, contexts, truncation=True, padding='max_length', max_length=512)\n",
        "\n",
        "        start_positions = []\n",
        "        end_positions = []\n",
        "\n",
        "        for i in range(len(questions)):\n",
        "            context = contexts[i]\n",
        "            if len(answers[i]['text']) == 0 or len(answers[i]['answer_start']) == 0:\n",
        "                start_positions.append(0)\n",
        "                end_positions.append(0)\n",
        "                continue\n",
        "\n",
        "            answer = answers[i]['text'][0]\n",
        "            answer_start = answers[i]['answer_start'][0]\n",
        "            answer_end = answer_start + len(answer)\n",
        "\n",
        "            # Tokenize context with the fast tokenizer\n",
        "            tokenized_context = tokenizer(context, truncation=True, padding='max_length', max_length=512)\n",
        "\n",
        "            # Find start and end token positions\n",
        "            start_token_idx = tokenized_context.char_to_token(answer_start)\n",
        "            end_token_idx = tokenized_context.char_to_token(answer_end - 1)\n",
        "\n",
        "            # Handle edge case where char_to_token returns None\n",
        "            if start_token_idx is None:\n",
        "                start_token_idx = 0\n",
        "            if end_token_idx is None:\n",
        "                end_token_idx = len(tokenized_context.input_ids) - 1\n",
        "\n",
        "            start_positions.append(start_token_idx)\n",
        "            end_positions.append(end_token_idx)\n",
        "\n",
        "        inputs.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
        "        return inputs\n",
        "\n",
        "    tokenized_datasets = dataset.map(preprocess_function, batched=True, remove_columns=dataset['train'].column_names)\n",
        "    return tokenized_datasets\n",
        "\n",
        "# Load the dataset\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"SajjadAyoubi/persian_qa\")\n",
        "\n",
        "# Tokenize the dataset\n",
        "tokenized_datasets = tokenize_dataset(dataset, tokenizer)\n",
        "print(tokenized_datasets)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-17T22:22:38.598385Z",
          "iopub.execute_input": "2024-06-17T22:22:38.599577Z",
          "iopub.status.idle": "2024-06-17T22:22:54.377446Z",
          "shell.execute_reply.started": "2024-06-17T22:22:38.599539Z",
          "shell.execute_reply": "2024-06-17T22:22:54.376528Z"
        },
        "trusted": true,
        "id": "Vb-InIriWFWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForQuestionAnswering, Trainer, TrainingArguments\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    evaluation_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    learning_rate=3e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=4,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=10,\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    greater_is_better=False,\n",
        ")\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-17T20:49:13.654695Z",
          "iopub.execute_input": "2024-06-17T20:49:13.655074Z",
          "iopub.status.idle": "2024-06-17T21:25:25.336255Z",
          "shell.execute_reply.started": "2024-06-17T20:49:13.655043Z",
          "shell.execute_reply": "2024-06-17T21:25:25.335073Z"
        },
        "trusted": true,
        "id": "ZD-MDFMMWFWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizerFast, BertForQuestionAnswering\n",
        "\n",
        "# Ensure the model and inputs are on the same device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "\n",
        "def evaluate_example(question, context, model, tokenizer):\n",
        "    # Move inputs to the same device as the model\n",
        "    inputs = tokenizer(question, context, return_tensors='pt', max_length=512, truncation=True).to(device)\n",
        "    outputs = model(**inputs)\n",
        "    start_logits = outputs.start_logits\n",
        "    end_logits = outputs.end_logits\n",
        "    start_idx = torch.argmax(start_logits)\n",
        "    end_idx = torch.argmax(end_logits)\n",
        "    answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][start_idx:end_idx + 1]))\n",
        "    return answer\n",
        "\n",
        "# Example question and context\n",
        "question = \"عنوان مقاله چیست؟\"\n",
        "context = \"این مقاله به بررسی تاثیرات آب و هوایی بر رشد گیاهان می‌پردازد.\"\n",
        "answer = evaluate_example(question, context, model, tokenizer)\n",
        "print(\"Predicted Answer:\", answer)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-17T21:33:32.809207Z",
          "iopub.execute_input": "2024-06-17T21:33:32.809791Z",
          "iopub.status.idle": "2024-06-17T21:33:32.842004Z",
          "shell.execute_reply.started": "2024-06-17T21:33:32.809752Z",
          "shell.execute_reply": "2024-06-17T21:33:32.84084Z"
        },
        "trusted": true,
        "id": "gjNyxKBuWFWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_example(question, context):\n",
        "    inputs = tokenizer(question, context, return_tensors='pt', max_length=512, truncation=True)\n",
        "    return inputs\n",
        "\n",
        "# Example question and context\n",
        "question = \"پایتخت اسپانیا کجاست؟\"\n",
        "context = \"مادرید، پایتخت اسپانیا، یکی از زیباترین شهرهای جهان است.\"\n",
        "\n",
        "tokenized_inputs = tokenize_example(question, context)\n",
        "print(\"Tokenized Inputs:\", tokenized_inputs)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-17T22:31:13.988838Z",
          "iopub.execute_input": "2024-06-17T22:31:13.989201Z",
          "iopub.status.idle": "2024-06-17T22:31:13.997903Z",
          "shell.execute_reply.started": "2024-06-17T22:31:13.989171Z",
          "shell.execute_reply": "2024-06-17T22:31:13.996913Z"
        },
        "trusted": true,
        "id": "UXvFM1QAWFWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BertTokenizerFast, BertForQuestionAnswering\n",
        "\n",
        "# Initialize the tokenizer and model\n",
        "tokenizer = BertTokenizerFast.from_pretrained('HooshvareLab/bert-fa-base-uncased')\n",
        "model = BertForQuestionAnswering.from_pretrained('HooshvareLab/bert-fa-base-uncased').cuda()\n",
        "\n",
        "# Example question and context\n",
        "question = \"پایتخت اسپانیا کجاست؟\"\n",
        "context = \"مادرید، پایتخت اسپانیا، یکی از زیباترین شهرهای جهان است.\"\n",
        "\n",
        "# Tokenize inputs\n",
        "inputs = tokenizer(question, context, return_tensors='pt', max_length=512, truncation=True)\n",
        "inputs = {key: value.cuda() for key, value in inputs.items()}  # Ensure inputs are on the correct device\n",
        "\n",
        "# Get model outputs\n",
        "outputs = model(**inputs)\n",
        "start_logits = outputs.start_logits\n",
        "end_logits = outputs.end_logits\n",
        "\n",
        "# Determine the start and end of the answer\n",
        "start_idx = torch.argmax(start_logits)\n",
        "end_idx = torch.argmax(end_logits)\n",
        "\n",
        "# Convert token IDs back to the answer string\n",
        "answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(inputs['input_ids'][0][start_idx:end_idx + 1]))\n",
        "print(\"Predicted Answer:\", answer)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-17T22:35:08.301659Z",
          "iopub.execute_input": "2024-06-17T22:35:08.30199Z",
          "iopub.status.idle": "2024-06-17T22:35:10.502424Z",
          "shell.execute_reply.started": "2024-06-17T22:35:08.301966Z",
          "shell.execute_reply": "2024-06-17T22:35:10.501326Z"
        },
        "trusted": true,
        "id": "t8uEX-CWWFWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jpbRQ8jkWFWt"
      }
    }
  ]
}