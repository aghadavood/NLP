{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 8704161,
          "sourceType": "datasetVersion",
          "datasetId": 5220742
        }
      ],
      "dockerImageVersionId": 30733,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "QAPersian-bert-base-multilingual-cased",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aghadavood/NLP/blob/main/QAPersian_bert_base_multilingual_cased.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'strart:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F5220742%2F8704161%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240618%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240618T220106Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D29616bd34a44e2a811a02833214cf6144ff71b17c1e3be29303de10f14e8ed1fdc8a4c8e1885df4d2c5eb2d9adf470b84d45de0d10648b2f9642e8471e943d77365d66cecba9e6088f82aa38e05b9c328d041b98d576f3b87aedae70b116645140dc7910bddc5c500c7e3e252cfb07ca6d4c7c4ad00888e21db971ccdf47bd9cbdc7f75cf86079000da1529be7134c112657bf15cb4a82d34720dd1ed448166f8da650621b784f67c5607df170c3f3a05a5a35a28c43e880c4abd4511ef758b0e50c2e70fb540f9b08217371d33050fa2023b011aa67fd3c4710fefaf6204b12f6e954fa4784f166d91485a249ad52c68ab270b689733cb04bddf4ac79d1dd98'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "pUolTil9Xj3M"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "raw",
      "source": [],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-06-15T20:34:41.242062Z",
          "iopub.execute_input": "2024-06-15T20:34:41.242438Z",
          "iopub.status.idle": "2024-06-15T20:34:59.405675Z",
          "shell.execute_reply.started": "2024-06-15T20:34:41.242405Z",
          "shell.execute_reply": "2024-06-15T20:34:59.404683Z"
        },
        "id": "Q1KdpEjLXj3W"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-17T19:52:14.067524Z",
          "iopub.execute_input": "2024-06-17T19:52:14.067874Z",
          "iopub.status.idle": "2024-06-17T19:53:04.111147Z",
          "shell.execute_reply.started": "2024-06-17T19:52:14.067844Z",
          "shell.execute_reply": "2024-06-17T19:53:04.110346Z"
        },
        "trusted": true,
        "id": "Y-yaTz_MXj3X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizerFast\n",
        "\n",
        "# Initialize the tokenizer\n",
        "tokenizer = BertTokenizerFast.from_pretrained('bert-base-multilingual-cased')\n",
        "\n",
        "def tokenize_dataset(dataset, tokenizer):\n",
        "    def preprocess_function(examples):\n",
        "        questions = examples['question']\n",
        "        contexts = examples['context']\n",
        "        answers = examples['answers']\n",
        "\n",
        "        inputs = tokenizer(questions, contexts, truncation=True, padding='max_length', max_length=512)\n",
        "\n",
        "        start_positions = []\n",
        "        end_positions = []\n",
        "\n",
        "        for i in range(len(questions)):\n",
        "            context = contexts[i]\n",
        "            if len(answers[i]['text']) == 0 or len(answers[i]['answer_start']) == 0:\n",
        "                start_positions.append(0)\n",
        "                end_positions.append(0)\n",
        "                continue\n",
        "\n",
        "            answer = answers[i]['text'][0]\n",
        "            answer_start = answers[i]['answer_start'][0]\n",
        "            answer_end = answer_start + len(answer)\n",
        "\n",
        "            # Tokenize context with the fast tokenizer\n",
        "            tokenized_context = tokenizer(context, truncation=True, padding='max_length', max_length=512)\n",
        "\n",
        "            # Find start and end token positions\n",
        "            start_token_idx = tokenized_context.char_to_token(answer_start)\n",
        "            end_token_idx = tokenized_context.char_to_token(answer_end - 1)\n",
        "\n",
        "            # Handle edge case where char_to_token returns None\n",
        "            if start_token_idx is None:\n",
        "                start_token_idx = 0\n",
        "            if end_token_idx is None:\n",
        "                end_token_idx = len(tokenized_context.input_ids) - 1\n",
        "\n",
        "            start_positions.append(start_token_idx)\n",
        "            end_positions.append(end_token_idx)\n",
        "\n",
        "        inputs.update({'start_positions': start_positions, 'end_positions': end_positions})\n",
        "        return inputs\n",
        "\n",
        "    tokenized_datasets = dataset.map(preprocess_function, batched=True, remove_columns=dataset['train'].column_names)\n",
        "    return tokenized_datasets\n",
        "\n",
        "# Load the dataset\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"SajjadAyoubi/persian_qa\")\n",
        "\n",
        "# Tokenize the dataset\n",
        "tokenized_datasets = tokenize_dataset(dataset, tokenizer)\n",
        "print(tokenized_datasets)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-17T11:32:44.178042Z",
          "iopub.execute_input": "2024-06-17T11:32:44.178879Z",
          "iopub.status.idle": "2024-06-17T11:33:15.775857Z",
          "shell.execute_reply.started": "2024-06-17T11:32:44.178844Z",
          "shell.execute_reply": "2024-06-17T11:33:15.774965Z"
        },
        "trusted": true,
        "id": "XojoK0NeXj3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertForQuestionAnswering, Trainer, TrainingArguments\n",
        "\n",
        "# Load the model\n",
        "model = BertForQuestionAnswering.from_pretrained('bert-base-multilingual-cased')\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    evaluation_strategy='epoch',\n",
        "    save_strategy='epoch',\n",
        "    learning_rate=3e-5,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=4,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=10,\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    greater_is_better=False,\n",
        ")\n",
        "\n",
        "# Initialize the Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets['train'],\n",
        "    eval_dataset=tokenized_datasets['validation'],\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate the model\n",
        "eval_results = trainer.evaluate()\n",
        "print(f\"Evaluation results: {eval_results}\")\n",
        "\n",
        "# Save the model and tokenizer\n",
        "model.save_pretrained('./fine_tuned_model')\n",
        "tokenizer.save_pretrained('./fine_tuned_model')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-17T11:45:06.37571Z",
          "iopub.execute_input": "2024-06-17T11:45:06.376075Z",
          "iopub.status.idle": "2024-06-17T12:23:15.36047Z",
          "shell.execute_reply.started": "2024-06-17T11:45:06.376044Z",
          "shell.execute_reply": "2024-06-17T12:23:15.359291Z"
        },
        "trusted": true,
        "id": "DfpOPjsfXj3a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "# Check tokenized dataset\n",
        "sample = random.choice(tokenized_datasets['train'])\n",
        "print(\"Sample Question:\", tokenizer.decode(sample['input_ids']))\n",
        "print(\"Start Position:\", sample['start_positions'])\n",
        "print(\"End Position:\", sample['end_positions'])\n",
        "print(\"Answer Tokens:\", tokenizer.decode(sample['input_ids'][sample['start_positions']:sample['end_positions'] + 1]))\n"
      ],
      "metadata": {
        "trusted": true,
        "id": "qbX2MVhwXj3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizerFast, BertForQuestionAnswering\n",
        "import torch\n",
        "\n",
        "# Load the fine-tuned model and tokenizer\n",
        "model = BertForQuestionAnswering.from_pretrained('./fine_tuned_model')\n",
        "tokenizer = BertTokenizerFast.from_pretrained('./fine_tuned_model')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-17T09:54:30.261733Z",
          "iopub.execute_input": "2024-06-17T09:54:30.26227Z",
          "iopub.status.idle": "2024-06-17T09:54:30.678995Z",
          "shell.execute_reply.started": "2024-06-17T09:54:30.262223Z",
          "shell.execute_reply": "2024-06-17T09:54:30.67787Z"
        },
        "trusted": true,
        "id": "ktCaggbnXj3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Define a Function to Predict Answers\n"
      ],
      "metadata": {
        "id": "yJ6qWZ92Xj3d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_answer(question, context):\n",
        "    inputs = tokenizer(question, context, return_tensors='pt', max_length=512, truncation=True)\n",
        "    outputs = model(**inputs)\n",
        "    start_scores = outputs.start_logits\n",
        "    end_scores = outputs.end_logits\n",
        "\n",
        "    # Get the most likely beginning and end of answer with the argmax of the score\n",
        "    start_index = torch.argmax(start_scores)\n",
        "    end_index = torch.argmax(end_scores) + 1\n",
        "\n",
        "    input_ids = inputs['input_ids'][0]\n",
        "    answer_tokens = tokenizer.convert_ids_to_tokens(input_ids[start_index:end_index])\n",
        "    answer = tokenizer.convert_tokens_to_string(answer_tokens)\n",
        "\n",
        "    return answer\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-17T09:23:26.592302Z",
          "iopub.execute_input": "2024-06-17T09:23:26.593178Z",
          "iopub.status.idle": "2024-06-17T09:23:26.689669Z",
          "shell.execute_reply.started": "2024-06-17T09:23:26.593144Z",
          "shell.execute_reply": "2024-06-17T09:23:26.685259Z"
        },
        "trusted": true,
        "id": "sn5R8EOQXj3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 3: Test the Model with Sample Inputs\n"
      ],
      "metadata": {
        "id": "cS1lHCDRXj3g"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-06-17T10:14:17.615811Z",
          "iopub.execute_input": "2024-06-17T10:14:17.616466Z",
          "iopub.status.idle": "2024-06-17T10:14:18.092672Z",
          "shell.execute_reply.started": "2024-06-17T10:14:17.616434Z",
          "shell.execute_reply": "2024-06-17T10:14:18.090777Z"
        },
        "trusted": true,
        "id": "7Ym8uIlHXj3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "check step by step , becasue the model return cls instead of answering right"
      ],
      "metadata": {
        "id": "ftP4k6wRXj3h"
      }
    }
  ]
}